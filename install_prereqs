#!/bin/bash -l
# ---------------------------------------------------------------
# Build “lora” env (Python‑3.10, NumPy‑1.26) for cluster PyTorch 2.2
# ---------------------------------------------------------------

module purge
module load anaconda/3/2023.03  gcc/12  cuda/12.1  openmpi_gpu/4.1
conda env remove -n lora -y 2>/dev/null
conda create -y -n lora python=3.10 "numpy<2"

eval "$(conda shell.bash hook)"
conda activate lora

# after: conda activate lora
export PYTHONNOUSERSITE=1

module load pytorch-distributed/gpu-cuda-12.1/2.2.0
export PATH="$CONDA_PREFIX/bin:$PATH"
export LD_LIBRARY_PATH="$CONDA_PREFIX/lib:${LD_LIBRARY_PATH:-}"

# …conda install block…

# wheels that depend on torch
pip install --no-cache-dir --no-deps \
      torchdata==0.7.1 bitsandbytes==0.45
      # torchdata==0.7.1 bitsandbytes==0.43.0
      # torchdata==0.7.1 bitsandbytes==0.43.3

# HF stack + helpers (normal deps)
pip install --no-cache-dir \
      transformers==4.40.2 peft==0.10.0 accelerate==0.28.0 \
      trl==0.8.6 datasets==2.19.0 deepspeed huggingface_hub==0.21.2 \
      tokenizers==0.19.1 sentencepiece protobuf wandb

pip install flash-attn --no-build-isolation